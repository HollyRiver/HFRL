{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de885c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/LLM/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftConfig, AutoPeftModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d672bef6",
   "metadata": {},
   "source": [
    "merge할 경우 성능 손실이 발생한다고 함 -> 어쩔 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40521293",
   "metadata": {},
   "source": [
    "`-` Merge Adapter and save pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215d70c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "adapter_name = \"results/lr5e-6/checkpoint-450\"\n",
    "save_directory = \"model/Zip-Llama-sft\"\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    adapter_name,\n",
    "    use_cache = True,\n",
    "    dtype = torch.bfloat16,\n",
    "    device_map = \"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c151783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6708dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd10e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.28s/it]\n",
      "/root/miniconda3/envs/LLM/lib/python3.12/site-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16\n",
    ")\n",
    "\n",
    "adapter_name = \"results/lr5e-6/checkpoint-450\"\n",
    "save_directory = \"model/Zip-Llama-sft\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(adapter_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    quantization_config = bnb_config,\n",
    "    use_cache = True,\n",
    "    dtype = torch.bfloat16,\n",
    "    device_map = \"cuda:0\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, adapter_name)\n",
    "\n",
    "model = model.merge_and_unload().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f300839",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type dtype is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m tokenizer = AutoTokenizer.from_pretrained(adapter_name)\n\u001b[32m      4\u001b[39m tokenizer.save_pretrained(save_directory)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM/lib/python3.12/site-packages/transformers/modeling_utils.py:3928\u001b[39m, in \u001b[36mPreTrainedModel.save_pretrained\u001b[39m\u001b[34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[39m\n\u001b[32m   3925\u001b[39m             \u001b[38;5;28msetattr\u001b[39m(model_to_save.generation_config, param_name, param_value)\n\u001b[32m   3926\u001b[39m             \u001b[38;5;28msetattr\u001b[39m(model_to_save.config, param_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m3928\u001b[39m     \u001b[43mmodel_to_save\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3929\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.can_generate():\n\u001b[32m   3930\u001b[39m     model_to_save.generation_config.save_pretrained(save_directory)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM/lib/python3.12/site-packages/transformers/configuration_utils.py:490\u001b[39m, in \u001b[36mPretrainedConfig.save_pretrained\u001b[39m\u001b[34m(self, save_directory, push_to_hub, **kwargs)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;66;03m# If we save using the predefined names, we can load using `from_pretrained`\u001b[39;00m\n\u001b[32m    488\u001b[39m output_config_file = os.path.join(save_directory, CONFIG_NAME)\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_json_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_config_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_diff\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConfiguration saved in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_config_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m push_to_hub:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM/lib/python3.12/site-packages/transformers/configuration_utils.py:1002\u001b[39m, in \u001b[36mPretrainedConfig.to_json_file\u001b[39m\u001b[34m(self, json_file_path, use_diff)\u001b[39m\n\u001b[32m    991\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    992\u001b[39m \u001b[33;03mSave this instance to a JSON file.\u001b[39;00m\n\u001b[32m    993\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    999\u001b[39m \u001b[33;03m        is serialized to JSON file.\u001b[39;00m\n\u001b[32m   1000\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file_path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m     writer.write(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_json_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_diff\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_diff\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM/lib/python3.12/site-packages/transformers/configuration_utils.py:988\u001b[39m, in \u001b[36mPretrainedConfig.to_json_string\u001b[39m\u001b[34m(self, use_diff)\u001b[39m\n\u001b[32m    986\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    987\u001b[39m     config_dict = \u001b[38;5;28mself\u001b[39m.to_dict()\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM/lib/python3.12/json/__init__.py:238\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM/lib/python3.12/json/encoder.py:202\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    200\u001b[39m chunks = \u001b[38;5;28mself\u001b[39m.iterencode(o, _one_shot=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     chunks = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m.join(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM/lib/python3.12/json/encoder.py:432\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    430\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM/lib/python3.12/json/encoder.py:406\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    408\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM/lib/python3.12/json/encoder.py:439\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    437\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCircular reference detected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    438\u001b[39m     markers[markerid] = o\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m o = \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM/lib/python3.12/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type dtype is not JSON serializable"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(save_directory)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_name)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99227ba1",
   "metadata": {},
   "source": [
    "`-` Saved model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "029b7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b139a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"model/Zip-Llama-sft\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, use_cache = True, device_map = \"cuda:0\", dtype = torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2009d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_ds = load_dataset(\"json\", data_files = \"data/dpo_resource.json\")[\"train\"]\n",
    "output_path = os.path.join(\"data\", f\"dpo_dataset_generated.csv\")\n",
    "\n",
    "results = []\n",
    "idx = 0\n",
    "\n",
    "ith_inference = {\"subject_id\" : gen_ds[idx][\"subject_id\"]}\n",
    "ith_inference[\"text\"] = gen_ds[idx][\"messages\"][1][\"content\"]\n",
    "\n",
    "for i in range(5):\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "                    gen_ds[idx][\"messages\"],\n",
    "                    add_generation_prompt=True,\n",
    "                    return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    terminators = [tokenizer.eos_token_id]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id=terminators,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=1.0,\n",
    "        top_p = 0.95\n",
    "    )\n",
    "\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    generation = tokenizer.decode(response, skip_special_tokens=True)\n",
    "    ith_inference[f\"Gen_{i}\"] = generation\n",
    "\n",
    "results.append(ith_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f9846d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subject_id': 14711614,\n",
       "  'text': \" \\r\\nName:  ___                    Unit No:   ___\\r\\n \\r\\nAdmission Date:  ___              Discharge Date:   ___\\r\\n \\r\\nDate of Birth:  ___             Sex:   F\\r\\n \\r\\nService: OBSTETRICS/GYNECOLOGY\\r\\n \\r\\nAllergies: \\r\\nReglan / Compazine / Viramune\\r\\n \\r\\nAttending: ___\\r\\n \\r\\nChief Complaint:\\r\\nVeritgo\\r\\n \\r\\nMajor Surgical or Invasive Procedure:\\r\\nlumbar puncture\\r\\n\\r\\n \\r\\nHistory of Present Illness:\\r\\n___ yo G3P1 at 19w3d WGA presents to gyn triage with persistent \\r\\nvertigo x 2 days. Worse with changes in position and upon \\r\\nlooking down, but also present when closes eyes and head is at \\r\\nrest. Had nausea, but no emesis. Denies tinnitus. Hearing is \\r\\nWNL. Denies headache. Denies visual changes. Denies weakness / \\r\\nsensory changes / falls. Of note, HIV meds changed ___. Has had \\r\\nsimilar sx prior to med change, resulting in a fall. However, \\r\\nthose sx resolved\\r\\nspontaneously and are now recurring.  Denies fevers / chills / \\r\\nGI symptoms. Denies dysuria / increased frequency. No pain \\r\\ncurrently. Denies recent colds. \\r\\n+ FM. NO VB / LOF / Ucx. \\r\\n\\r\\n \\r\\nPast Medical History:\\r\\nPOBHx: G3P1, c/s x 1, ectopic x 1\\r\\nPMH: \\r\\n*) HIV:\\r\\n- Followed by Dr. ___ HIV regimen changed ___ to\\r\\ndarunavir, etravirine, and truvada ___ elevated VL (VL 317\\r\\n___\\r\\n- most recent VL < 50, CD4 475 ___ \\r\\n\\r\\n*) h/o Hepatitis B:\\r\\n- diagnosed in childhood in ___\\r\\n- Serology of - HbsAg, + HbcAb, and + HbsAb indicative of prior\\r\\ninfection, now cleared\\r\\n- baseline LFTs at 10 wks ega wnl\\r\\n\\r\\n*) cHTN: \\r\\n- BBP 126/80 at 5 wks while on Norvasc 5 mg qd\\r\\n- Norvasc dc'd at 10wks gestation\\r\\n- Baseline PIH labs at 10 wks wnl\\r\\n \\r\\n\\r\\n \\r\\nPhysical Exam:\\r\\nO: 98.1  93  121/86  18  100%RA\\r\\nNeuro: a&o x 3, CN II-XII intact except lateral 4sec nystagmus\\r\\nwith R lateral gaze. No vertical nystagmus. Motor, sensory\\r\\ngrossly intact b/l. No pronator drift. \\r\\ncerebellar: nose-finger intact. Rapid alternating mvmt intact.\\r\\nReflexes: 1+ equal, b/l biceps, brachioradialis, patellar\\r\\nGait: widened gait.\\r\\n___ Hall pike: nystagmus with head R lateral, extended position.\\r\\nCor: RRR\\r\\nPulm: CTAB\\r\\nABD:  soft, NT, ND\\r\\n\\r\\n \\r\\nPertinent Results:\\r\\nEKG: NSR, NA, NI, no ST changes. \\r\\n\\r\\n___ \\r\\nCBC: 5.4 < 11.6 / 32.4 > 281 \\r\\nlytes: P\\r\\nUA: P\\r\\n\\r\\n \\r\\nBrief Hospital Course:\\r\\nThe patient was admited to the ___ service for servere \\r\\nvertigo. Neurology was consulted and given her symptoms of \\r\\nvertigo in the setting of HIV, they recomended a MRI and a \\r\\nlumbar puncture. The MRI was normal. On ___ she had this lumbar \\r\\npuncture which was negative. Neurology believed the vertigo was \\r\\nsecondary to peripheral vestibulopathy.They instructed the \\r\\npatient to do maneuvers to decrease her vertigo. They \\r\\nrecommended she take 25 mg meclizine for breakthrough symptoms. \\r\\nInfectious disease was also consulted during this \\r\\nhospitalization. They did not believe her recent HIV medication \\r\\nchange were causing the vertigo. They recommended continuing her \\r\\ncurrent HIV medication regimen. She was discharged on home on \\r\\n___. She will follow up in the high risk outpatient clinic on \\r\\n___.\\r\\n \\r\\nMedications on Admission:\\r\\nPOBHx: G3P1, c/s x 1, ectopic x 1\\r\\nPMH: HIV, h/o HepB(- HbsAg, + HbcAb, and + HbsAb), cHTN, \\r\\n \\r\\nDischarge Medications:\\r\\n1. Docusate Sodium 100 mg Capsule Sig: One (1) Capsule PO BID (2 \\r\\ntimes a day) as needed.  \\r\\n2. Acetaminophen 325 mg Tablet Sig: Two (2) Tablet PO Q6H (every \\r\\n6 hours) as needed.  \\r\\n3. B Complex-Vitamin C-Folic Acid 1 mg Capsule Sig: One (1) Cap \\r\\nPO DAILY (Daily).  \\r\\n4. Darunavir 300 mg Tablet Sig: Two (2) Tablet PO BID (2 times a \\r\\nday).  \\r\\n5. Emtricitabine-Tenofovir 200-300 mg Tablet Sig: One (1) Tablet \\r\\nPO DAILY (Daily).  \\r\\n6. Lorazepam 0.5 mg Tablet Sig: One (1) Tablet PO Q4H (every 4 \\r\\nhours) as needed for symtpoms of vertigo.  \\r\\n7. Ritonavir 100 mg Capsule Sig: One (1) Capsule PO BID (2 times \\r\\na day).  \\r\\n8. Etravirine 100 mg Tablet Sig: Two (2) Tablet PO BID (2 times \\r\\na day).  \\r\\n9. Meclizine 12.5 mg Tablet Sig: ___ Tablets PO once a day as \\r\\nneeded for prn vertigo.  \\r\\n\\r\\n \\r\\nDischarge Disposition:\\r\\nHome\\r\\n \\r\\nDischarge Diagnosis:\\r\\nbenign positional vertigo\\r\\n\\r\\n \\r\\nDischarge Condition:\\r\\nstable\\r\\n\\r\\n \\r\\nDischarge Instructions:\\r\\nPlease call for uncontrollable vertigo, contractions, leakage of \\r\\nfluid, decreased fetal movement, falls or abdominal trauma, \\r\\nfevers/chills, any concerns.\\r\\n\\r\\n \\r\\nFollowup Instructions:\\r\\n___\\r\\n\",\n",
       "  'Gen_0': 'A 19-year-old female at 19 weeks and 3 days gestation presents with symptoms of benign positional vertigo, characterized by episodic vertigo without hearing loss, tinnitus, or headache, with nystagmus on lateral gaze and a widened gait, following a change in HIV medication, which was previously associated with a similar symptom complex.',\n",
       "  'Gen_1': 'Here is the extracted sentence for hazard calculation:\\n\\n\"A 19-week pregnant woman with history of HIV, hepatitis B, and hypertension presented with 2-day history of worsening vertigo with positional changes and head movement, accompanied by nausea, but no tinnitus, hearing loss, headache, or visual changes, with a negative lumbar puncture and normal MRI.\"\\n\\nThis sentence captures the key clinical information, including the patient\\'s chief complaint (vertigo), relevant medical history (HIV, hepatitis B, and hypertension), physical examination findings (nausea, nystagmus, and widened gait), and diagnostic results (negative lumbar puncture and normal MRI).',\n",
       "  'Gen_2': \"Here is a single sentence summarizing the patient's Chief Complaint, Physical Exam, and Admission Labs (Pertinent Results):\\n\\nA 19-week pregnant woman (G3P1) with a history of HIV presented with 2-day history of persistent vertigo, worse with positional changes, and had a normal MRI and lumbar puncture; physical examination revealed nystagmus with right lateral gaze, widened gait, and intact cranial nerves II-XII; laboratory results showed a normal EKG, CBC, and UA.\",\n",
       "  'Gen_3': 'A pregnant woman (19 weeks gestation) with a history of HIV and recent change in medication presented with vertigo, nystagmus, and widened gait, with normal MRI and lumbar puncture results; her condition was stable and discharged with a diagnosis of benign positional vertigo.',\n",
       "  'Gen_4': 'Here is the extracted information in one sentence for hazard calculation:\\n\\nA 26-year-old female patient, G3P1, at 19 weeks of gestation with a history of HIV and prior vertigo episodes, presented with persistent vertigo, worsened by head position changes, with a negative lumbar puncture and normal MRI, leading to a diagnosis of benign positional vertigo.'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12572af4",
   "metadata": {},
   "source": [
    "`-` 지랄남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8871108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97af6e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330aeedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.89s/it]\n"
     ]
    }
   ],
   "source": [
    "adapter_name = \"results/lr5e-6/checkpoint-450\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(adapter_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    quantization_config = bnb_config,\n",
    "    use_cache = True,\n",
    "    dtype = torch.bfloat16,\n",
    "    device_map = \"cuda:0\"\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, adapter_name)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_name, use_fast = True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "375d706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(adapter_name, use_fast = True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc100d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_ds = load_dataset(\"json\", data_files = \"data/dpo_resource.json\")[\"train\"]\n",
    "output_path = os.path.join(\"data\", f\"dpo_dataset_generated.csv\")\n",
    "\n",
    "results = []\n",
    "idx = 0\n",
    "\n",
    "ith_inference = {\"subject_id\" : gen_ds[idx][\"subject_id\"]}\n",
    "ith_inference[\"text\"] = gen_ds[idx][\"messages\"][1][\"content\"]\n",
    "\n",
    "for i in range(5):\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "                    gen_ds[idx][\"messages\"],\n",
    "                    add_generation_prompt=True,\n",
    "                    return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    terminators = [tokenizer.eos_token_id]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=1024,\n",
    "        eos_token_id=terminators,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=1.0,\n",
    "        top_p = 0.95\n",
    "    )\n",
    "\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    generation = tokenizer.decode(response, skip_special_tokens=True)\n",
    "    ith_inference[f\"Gen_{i}\"] = generation\n",
    "\n",
    "results.append(ith_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e6bcc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subject_id': 14711614,\n",
       "  'text': \" \\r\\nName:  ___                    Unit No:   ___\\r\\n \\r\\nAdmission Date:  ___              Discharge Date:   ___\\r\\n \\r\\nDate of Birth:  ___             Sex:   F\\r\\n \\r\\nService: OBSTETRICS/GYNECOLOGY\\r\\n \\r\\nAllergies: \\r\\nReglan / Compazine / Viramune\\r\\n \\r\\nAttending: ___\\r\\n \\r\\nChief Complaint:\\r\\nVeritgo\\r\\n \\r\\nMajor Surgical or Invasive Procedure:\\r\\nlumbar puncture\\r\\n\\r\\n \\r\\nHistory of Present Illness:\\r\\n___ yo G3P1 at 19w3d WGA presents to gyn triage with persistent \\r\\nvertigo x 2 days. Worse with changes in position and upon \\r\\nlooking down, but also present when closes eyes and head is at \\r\\nrest. Had nausea, but no emesis. Denies tinnitus. Hearing is \\r\\nWNL. Denies headache. Denies visual changes. Denies weakness / \\r\\nsensory changes / falls. Of note, HIV meds changed ___. Has had \\r\\nsimilar sx prior to med change, resulting in a fall. However, \\r\\nthose sx resolved\\r\\nspontaneously and are now recurring.  Denies fevers / chills / \\r\\nGI symptoms. Denies dysuria / increased frequency. No pain \\r\\ncurrently. Denies recent colds. \\r\\n+ FM. NO VB / LOF / Ucx. \\r\\n\\r\\n \\r\\nPast Medical History:\\r\\nPOBHx: G3P1, c/s x 1, ectopic x 1\\r\\nPMH: \\r\\n*) HIV:\\r\\n- Followed by Dr. ___ HIV regimen changed ___ to\\r\\ndarunavir, etravirine, and truvada ___ elevated VL (VL 317\\r\\n___\\r\\n- most recent VL < 50, CD4 475 ___ \\r\\n\\r\\n*) h/o Hepatitis B:\\r\\n- diagnosed in childhood in ___\\r\\n- Serology of - HbsAg, + HbcAb, and + HbsAb indicative of prior\\r\\ninfection, now cleared\\r\\n- baseline LFTs at 10 wks ega wnl\\r\\n\\r\\n*) cHTN: \\r\\n- BBP 126/80 at 5 wks while on Norvasc 5 mg qd\\r\\n- Norvasc dc'd at 10wks gestation\\r\\n- Baseline PIH labs at 10 wks wnl\\r\\n \\r\\n\\r\\n \\r\\nPhysical Exam:\\r\\nO: 98.1  93  121/86  18  100%RA\\r\\nNeuro: a&o x 3, CN II-XII intact except lateral 4sec nystagmus\\r\\nwith R lateral gaze. No vertical nystagmus. Motor, sensory\\r\\ngrossly intact b/l. No pronator drift. \\r\\ncerebellar: nose-finger intact. Rapid alternating mvmt intact.\\r\\nReflexes: 1+ equal, b/l biceps, brachioradialis, patellar\\r\\nGait: widened gait.\\r\\n___ Hall pike: nystagmus with head R lateral, extended position.\\r\\nCor: RRR\\r\\nPulm: CTAB\\r\\nABD:  soft, NT, ND\\r\\n\\r\\n \\r\\nPertinent Results:\\r\\nEKG: NSR, NA, NI, no ST changes. \\r\\n\\r\\n___ \\r\\nCBC: 5.4 < 11.6 / 32.4 > 281 \\r\\nlytes: P\\r\\nUA: P\\r\\n\\r\\n \\r\\nBrief Hospital Course:\\r\\nThe patient was admited to the ___ service for servere \\r\\nvertigo. Neurology was consulted and given her symptoms of \\r\\nvertigo in the setting of HIV, they recomended a MRI and a \\r\\nlumbar puncture. The MRI was normal. On ___ she had this lumbar \\r\\npuncture which was negative. Neurology believed the vertigo was \\r\\nsecondary to peripheral vestibulopathy.They instructed the \\r\\npatient to do maneuvers to decrease her vertigo. They \\r\\nrecommended she take 25 mg meclizine for breakthrough symptoms. \\r\\nInfectious disease was also consulted during this \\r\\nhospitalization. They did not believe her recent HIV medication \\r\\nchange were causing the vertigo. They recommended continuing her \\r\\ncurrent HIV medication regimen. She was discharged on home on \\r\\n___. She will follow up in the high risk outpatient clinic on \\r\\n___.\\r\\n \\r\\nMedications on Admission:\\r\\nPOBHx: G3P1, c/s x 1, ectopic x 1\\r\\nPMH: HIV, h/o HepB(- HbsAg, + HbcAb, and + HbsAb), cHTN, \\r\\n \\r\\nDischarge Medications:\\r\\n1. Docusate Sodium 100 mg Capsule Sig: One (1) Capsule PO BID (2 \\r\\ntimes a day) as needed.  \\r\\n2. Acetaminophen 325 mg Tablet Sig: Two (2) Tablet PO Q6H (every \\r\\n6 hours) as needed.  \\r\\n3. B Complex-Vitamin C-Folic Acid 1 mg Capsule Sig: One (1) Cap \\r\\nPO DAILY (Daily).  \\r\\n4. Darunavir 300 mg Tablet Sig: Two (2) Tablet PO BID (2 times a \\r\\nday).  \\r\\n5. Emtricitabine-Tenofovir 200-300 mg Tablet Sig: One (1) Tablet \\r\\nPO DAILY (Daily).  \\r\\n6. Lorazepam 0.5 mg Tablet Sig: One (1) Tablet PO Q4H (every 4 \\r\\nhours) as needed for symtpoms of vertigo.  \\r\\n7. Ritonavir 100 mg Capsule Sig: One (1) Capsule PO BID (2 times \\r\\na day).  \\r\\n8. Etravirine 100 mg Tablet Sig: Two (2) Tablet PO BID (2 times \\r\\na day).  \\r\\n9. Meclizine 12.5 mg Tablet Sig: ___ Tablets PO once a day as \\r\\nneeded for prn vertigo.  \\r\\n\\r\\n \\r\\nDischarge Disposition:\\r\\nHome\\r\\n \\r\\nDischarge Diagnosis:\\r\\nbenign positional vertigo\\r\\n\\r\\n \\r\\nDischarge Condition:\\r\\nstable\\r\\n\\r\\n \\r\\nDischarge Instructions:\\r\\nPlease call for uncontrollable vertigo, contractions, leakage of \\r\\nfluid, decreased fetal movement, falls or abdominal trauma, \\r\\nfevers/chills, any concerns.\\r\\n\\r\\n \\r\\nFollowup Instructions:\\r\\n___\\r\\n\",\n",
       "  'Gen_0': \"Here is one sentence that can be used for hazard calculation, based on the information provided:\\n\\nThe patient, a 19-week pregnant woman, was admitted with a chief complaint of severe vertigo, which resolved following a lumbar puncture, and was discharged with a diagnosis of benign positional vertigo.\\n\\nHowever, to be more clinically accurate and concise, a more specific sentence could be:\\n\\nSevere vertigo improved with lumbar puncture and resolved after discharge in a 19-week pregnant woman.\\n\\nThis sentence is more suitable for hazard calculation because it:\\n\\n* Clearly states the patient's condition (severe vertigo)\\n* Mentions the intervention that improved the condition (lumbar puncture)\\n* Provides relevant demographic information (19-week pregnant woman)\\n* Conveys a clear outcome (resolved after discharge)\",\n",
       "  'Gen_1': \"Here is one sentence that summarizes the patient's condition for hazard calculation:\\n\\nA 19-week pregnant woman with a history of HIV, hypertension, and previous cerebellar symptoms presents with benign paroxysmal positional vertigo, with recent HIV medication change and history of similar symptoms leading to a fall, now resolved with a negative lumbar puncture and initiation of vertigo management.\",\n",
       "  'Gen_2': 'Here is a one-sentence summary for hazard calculation, based on the Chief Complaint, Physical Exam, and Admission Labs:\\n\\n\"A 19-week pregnant woman with a history of HIV and previous similar symptoms presents with persistent vertigo, nystagmus, and widened gait, with a normal MRI but negative lumbar puncture, suggestive of benign positional vertigo.\"\\n\\nThis sentence is clinically accurate, concise, and precise, making it suitable for hazard calculation.',\n",
       "  'Gen_3': 'Here are the extracted sentences for hazard calculation:\\n\\n1. Chief Complaint: \"This [19w3d] pregnant woman at 20 weeks gestation presents with persistent vertigo.\"\\n2. Physical Exam: \"Neuro: a&o x 3, CN II-XII intact except lateral 4sec nystagmus with R lateral gaze.\"\\n3. Pertinent Results: \"CBC: 5.4 < 11.6 / 32.4 > 281.\"\\n\\nThese sentences can be used for hazard calculation by extracting relevant information, such as:\\n\\n* Duration of vertigo: 2 days\\n* Type of vertigo: benign positional vertigo\\n* Presence of nystagmus: present (lateral 4sec nystagmus with R lateral gaze)\\n* Normal vital signs: BP 121/86, HR 93, RR 18\\n* Normal CBC results: hemoglobin 11.6, hematocrit 32.4\\n* HIV medication regimen: darunavir, etravirine, and truvada\\n\\nThese factors can be used to calculate the hazard of future complications or hospitalizations related to the patient\\'s condition.',\n",
       "  'Gen_4': 'Here are the extracted information in one sentence for hazard calculation:\\n\\n\"A 19-week pregnant woman with a history of HIV, benign positional vertigo, and previous fall due to vertigo symptoms presents with recurrent vertigo worsening with positional changes and treatment with darunavir, etravirine, and truvada with elevated viral load.\"\\n\\nHowever, for hazard calculation purposes, the sentence should be more concise and clinically focused. Here is a revised sentence:\\n\\n\"Vertigo in a 19-week pregnant HIV patient with recurrent symptoms after medication change and previous fall.\"\\n\\nThis revised sentence isolates the key clinical features and eliminates non-essential information to provide a precise and clinically accurate hazard calculation.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53bb724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
