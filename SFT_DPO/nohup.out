Traceback (most recent call last):
  File "/root/HFRL/SFT_DPO/SFT.py", line 16, in <module>
    from sklearn.model_selection import train_test_split
ModuleNotFoundError: No module named 'sklearn'
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 23000 examples [00:00, 187652.93 examples/s]Generating train split: 27412 examples [00:00, 200291.03 examples/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 3046 examples [00:00, 360319.54 examples/s]
======== Log a few random samples from the processed training set ========
<|begin_of_text|><|start_header_id|>user<|end_header_id|>

Write a third person narrative story of at least 1000 words about a young woman who gets trapped in an old mansion that is reputed to be haunted by the ghosts of its former residents. The protagonist should be a curious and resourceful character who must use her wits, intuition, and problem-solving skills to unravel the mystery behind the strange happenings in the house. The story should be suspenseful and atmospheric, with vivid descriptions of the mansion's eerie interiors, creepy sounds, and unsettling events. The protagonist should encounter a variety of supernatural phenomena, such as apparitions, poltergeist activity, and unexplained phenomena, and must piece together clues from the house's past to uncover the truth behind the haunting. As the story progresses, the protagonist should become more and more involved in the house's dark secrets, until the final reveal of the true nature of the haunting. The resolution should be satisfying and should provide closure to the story, even if there are some loose ends left unanswered. The story should be well-written and polished, with a clear and engaging writing style that captures the reader's attention from the first sentence to the last.<|eot_id|><|start_header_id|>assistant<|end_header_id|>

In the depths of the countryside, nestled within a dense forest, stood an old mansion that had been abandoned for decades. Its grandeur was still apparent, despite the peeling paint and overgrown gardens. The mansion had a reputation for being haunted by the ghosts of its former residents, and many brave souls had attempted to explore its mysteries, but none had ever returned.

Enter our protagonist, a young woman named Lily, who had always had a fascination with the paranormal. She had heard stories of the haunted mansion and was determined to uncover its secrets. Without hesitation, she packed her bags, set out on her journey, and arrived at the mansion's crumbling gates in the evening.

As she stepped inside, Lily felt a chill run down her spine. The air inside was heavy with the scent of decay and dampness. She began to explore the mansion, her eyes scanning the dimly lit rooms and her ears straining to listen for any signs of life. The creaking wooden floors and the distant howling of wind created an eerie atmosphere, making her skin crawl.

As she wandered deeper into the mansion, Lily started to notice strange occurrences. Doors would slam shut on their own, and she would hear whispers in the darkness. She tried to brush it off as the wind, but her intuition told her otherwise. She began to feel like she was being watched, and the hairs on the back of her neck stood on end.

One night, as she was exploring the attic, she saw a shadowy figure darting around the corner. Her heart raced as she chased after it, but it vanished into thin air. She knew then that she was not alone in the mansion, and that something supernatural was lurking in the shadows.

Over the next few days, Lily encountered more and more inexplicable events. She would see apparitions in the windows, and hear footsteps in the hallways. She found a room filled with antique objects, all of which seemed to be staring at her with cold, dead eyes. She began to feel trapped, as if the house itself was trying to keep her there.

Determined to uncover the truth behind the haunting, Lily began to research the mansion's history. She discovered that it had been built on the site of an ancient burial ground, and that the family who had lived there had been plagued by supernatural occurrences. She also found old newspapers clippings that told the tale of a young girl who had died in the mansion under mysterious circumstances.

As she delved deeper into the mystery, Lily encountered more and more evidence of the paranormal. She saw ghostly apparitions, and experienced unexplained phenomena such as objects moving on their own. She began to feel like she was a part of the haunting, and that the house was trying to communicate with her.

One night, as she was exploring the basement, she came across a hidden room. Inside, she found a series of journals belonging to the family who had once lived in the mansion. As she read through them, she discovered that the young girl who had died had been the daughter of the family, and that her death had been shrouded in mystery.

The journals revealed that the girl had been playing with a mysterious object, a small box with strange symbols etched onto its surface. Suddenly, the box had started to glow, and the girl had been consumed by it. The family had tried to investigate, but the box had disappeared, and the girl had been found dead.

Lily realized that the box was the source of the haunting. She knew that she had to find it and put an end to the curse. She searched the mansion from top to bottom, her heart racing as she finally found the box in the attic. As she touched it, she felt a surge of energy, and the ghostly apparitions vanished.

The box was destroyed, and the haunting came to an end. Lily left the mansion, feeling a sense of closure and accomplishment. She knew that she had uncovered the truth behind the haunting, and that she had put an end to the curse that had plagued the mansion for decades.

As she drove away, she looked back at the mansion, knowing that she would never forget the strange and supernatural events that had taken place there. She had faced her fears and uncovered a dark secret, and she knew that she would always<|eot_id|>
<|begin_of_text|><|start_header_id|>user<|end_header_id|>

I want to create a website that sells educational videos like Class 101. Please tell me how to use a free video player
Answer in English.지금 번역하기<|eot_id|><|start_header_id|>assistant<|end_header_id|>

To create a website that sells educational videos, you will need to use a free video player to embed your videos on the site. Here's how you can use one:

1. Choose a free video player: There are several free video players available, such as Video.js, JW Player, or Plex. Choose the one that suits your needs.
2. Download the player: Visit the website of the video player you chose and download the necessary files.
3. Install the player on your website: To install the video player, you will need to upload the downloaded files to your web server using an FTP client or your hosting provider's file manager. The exact process may vary depending on the video player you chose.
4. Embed the player on your web page: To embed the video player on your website, you will need to add a shortcode or HTML code to the page. This will typically be provided by the video player's documentation.

Here's an example using Video.js, a popular open-source JavaScript and CSS library for working with HTML5 video:

1. Download and install Video.js: Go to the Video.js website (<https://videojs.com/>), download the necessary files, and install them on your website.
2. Load the Video.js library: Add the following code to the head of the HTML document where you want to embed the player:
```html
<link rel="stylesheet" href="path/to/video-js.css">
<script src="path/to/video.js"></script>
```
Replace "path/to/video-js.css" and "path/to/video.js" with the actual paths to the Video.js CSS and JavaScript files on your web server.

1. Create the video player: On the same HTML document, add an empty `<video>` element with the necessary attributes:
```html
<video id="myVideoPlayer" class="vjs-default-skin" controls>
  <source src="path/to/your/video.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>
```
Replace "id" with a unique identifier for your video player, "path/to/your/video.mp4" with the actual path to your video file on your web server, and "controls" with the video file format that you're using.

1. Initialize Video.js: Add the following JavaScript code anywhere in the HTML document, preferably just before the closing `</body>` tag:
```javascript
<script>
  videojs("myVideoPlayer", {
    "techOrder": ["flash"]
  });
</script>
```
Replace "myVideoPlayer" with the unique identifier you specified earlier.

Now, when you load your web page, you should see a functional video player with playback controls, video quality settings, and other features provided by the video player library.

Remember to customize the player's appearance and behavior according to your website's style and requirements. You can find more information on customization and other features in the video player's documentation.<|eot_id|>
Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files:  25%|██▌       | 1/4 [02:03<06:09, 123.09s/it]Fetching 4 files:  75%|███████▌  | 3/4 [02:03<00:31, 31.99s/it] Fetching 4 files: 100%|██████████| 4/4 [02:03<00:00, 30.83s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.88s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.13s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.41s/it]
Tokenizing train dataset:   0%|          | 0/27412 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 103/27412 [00:00<00:26, 1017.38 examples/s]Tokenizing train dataset:   1%|          | 224/27412 [00:00<00:24, 1127.26 examples/s]Tokenizing train dataset:   1%|▏         | 365/27412 [00:00<00:21, 1248.58 examples/s]Tokenizing train dataset:   2%|▏         | 493/27412 [00:00<00:21, 1245.77 examples/s]Tokenizing train dataset:   2%|▏         | 633/27412 [00:00<00:20, 1292.78 examples/s]Tokenizing train dataset:   3%|▎         | 771/27412 [00:00<00:20, 1321.27 examples/s]Tokenizing train dataset:   4%|▎         | 969/27412 [00:00<00:20, 1318.41 examples/s]Tokenizing train dataset:   4%|▍         | 1134/27412 [00:00<00:24, 1065.01 examples/s]Tokenizing train dataset:   5%|▍         | 1261/27412 [00:01<00:23, 1109.43 examples/s]Tokenizing train dataset:   5%|▌         | 1392/27412 [00:01<00:22, 1157.92 examples/s]Tokenizing train dataset:   6%|▌         | 1522/27412 [00:01<00:21, 1191.71 examples/s]Tokenizing train dataset:   6%|▌         | 1656/27412 [00:01<00:20, 1230.09 examples/s]Tokenizing train dataset:   7%|▋         | 1788/27412 [00:01<00:20, 1254.78 examples/s]Tokenizing train dataset:   7%|▋         | 1920/27412 [00:01<00:20, 1268.92 examples/s]Tokenizing train dataset:   8%|▊         | 2064/27412 [00:01<00:24, 1051.57 examples/s]Tokenizing train dataset:   8%|▊         | 2193/27412 [00:01<00:22, 1102.75 examples/s]Tokenizing train dataset:   8%|▊         | 2317/27412 [00:01<00:22, 1137.61 examples/s]Tokenizing train dataset:   9%|▉         | 2446/27412 [00:02<00:21, 1176.82 examples/s]Tokenizing train dataset:   9%|▉         | 2571/27412 [00:02<00:20, 1194.66 examples/s]Tokenizing train dataset:  10%|█         | 2762/27412 [00:02<00:20, 1220.41 examples/s]Tokenizing train dataset:  11%|█         | 2890/27412 [00:02<00:19, 1233.57 examples/s]Tokenizing train dataset:  11%|█         | 3066/27412 [00:02<00:23, 1047.64 examples/s]Tokenizing train dataset:  12%|█▏        | 3192/27412 [00:02<00:22, 1093.93 examples/s]Tokenizing train dataset:  12%|█▏        | 3322/27412 [00:02<00:21, 1141.41 examples/s]Tokenizing train dataset:  13%|█▎        | 3507/27412 [00:02<00:20, 1169.75 examples/s]Tokenizing train dataset:  13%|█▎        | 3642/27412 [00:03<00:19, 1208.97 examples/s]Tokenizing train dataset:  14%|█▍        | 3774/27412 [00:03<00:19, 1234.38 examples/s]Tokenizing train dataset:  14%|█▍        | 3911/27412 [00:03<00:18, 1268.25 examples/s]Tokenizing train dataset:  15%|█▍        | 4059/27412 [00:03<00:22, 1052.75 examples/s]Tokenizing train dataset:  15%|█▌        | 4192/27412 [00:03<00:20, 1118.48 examples/s]Tokenizing train dataset:  16%|█▌        | 4321/27412 [00:03<00:19, 1159.67 examples/s]Tokenizing train dataset:  16%|█▋        | 4460/27412 [00:03<00:18, 1213.95 examples/s]Tokenizing train dataset:  17%|█▋        | 4588/27412 [00:03<00:18, 1224.65 examples/s]Tokenizing train dataset:  17%|█▋        | 4726/27412 [00:03<00:17, 1263.61 examples/s]Tokenizing train dataset:  18%|█▊        | 4869/27412 [00:04<00:17, 1309.87 examples/s]Tokenizing train dataset:  18%|█▊        | 5062/27412 [00:04<00:20, 1114.34 examples/s]Tokenizing train dataset:  19%|█▉        | 5183/27412 [00:04<00:19, 1133.39 examples/s]Tokenizing train dataset:  19%|█▉        | 5312/27412 [00:04<00:18, 1171.19 examples/s]Tokenizing train dataset:  20%|█▉        | 5438/27412 [00:04<00:18, 1192.26 examples/s]Tokenizing train dataset:  20%|██        | 5619/27412 [00:04<00:18, 1190.56 examples/s]Tokenizing train dataset:  21%|██        | 5747/27412 [00:04<00:17, 1211.75 examples/s]Tokenizing train dataset:  21%|██▏       | 5872/27412 [00:04<00:17, 1218.88 examples/s]Tokenizing train dataset:  22%|██▏       | 6000/27412 [00:05<00:20, 1039.37 examples/s]Tokenizing train dataset:  22%|██▏       | 6122/27412 [00:05<00:19, 1082.88 examples/s]Tokenizing train dataset:  23%|██▎       | 6244/27412 [00:05<00:18, 1114.77 examples/s]Tokenizing train dataset:  23%|██▎       | 6372/27412 [00:05<00:18, 1159.02 examples/s]Tokenizing train dataset:  24%|██▎       | 6507/27412 [00:05<00:17, 1210.49 examples/s]Tokenizing train dataset:  24%|██▍       | 6649/27412 [00:05<00:16, 1267.27 examples/s]Tokenizing train dataset:  25%|██▍       | 6838/27412 [00:05<00:16, 1256.04 examples/s]Tokenizing train dataset:  25%|██▌       | 6975/27412 [00:05<00:15, 1279.29 examples/s]Tokenizing train dataset:  26%|██▌       | 7125/27412 [00:06<00:19, 1059.52 examples/s]Tokenizing train dataset:  26%|██▋       | 7261/27412 [00:06<00:17, 1127.19 examples/s]Tokenizing train dataset:  27%|██▋       | 7396/27412 [00:06<00:16, 1181.39 examples/s]Tokenizing train dataset:  27%|██▋       | 7526/27412 [00:06<00:16, 1208.08 examples/s]Tokenizing train dataset:  28%|██▊       | 7658/27412 [00:06<00:15, 1237.80 examples/s]Tokenizing train dataset:  29%|██▊       | 7841/27412 [00:06<00:16, 1219.61 examples/s]Tokenizing train dataset:  29%|██▉       | 7985/27412 [00:06<00:15, 1272.81 examples/s]Tokenizing train dataset:  30%|██▉       | 8120/27412 [00:06<00:18, 1052.74 examples/s]Tokenizing train dataset:  30%|███       | 8255/27412 [00:07<00:17, 1120.85 examples/s]Tokenizing train dataset:  31%|███       | 8377/27412 [00:07<00:16, 1143.38 examples/s]Tokenizing train dataset:  31%|███       | 8501/27412 [00:07<00:16, 1163.95 examples/s]Tokenizing train dataset:  31%|███▏      | 8634/27412 [00:07<00:15, 1199.51 examples/s]Tokenizing train dataset:  32%|███▏      | 8764/27412 [00:07<00:15, 1221.12 examples/s]Tokenizing train dataset:  32%|███▏      | 8904/27412 [00:07<00:14, 1265.44 examples/s]Tokenizing train dataset:  33%|███▎      | 9064/27412 [00:07<00:16, 1081.57 examples/s]Tokenizing train dataset:  34%|███▎      | 9194/27412 [00:07<00:16, 1132.71 examples/s]Tokenizing train dataset:  34%|███▍      | 9324/27412 [00:07<00:15, 1169.97 examples/s]Tokenizing train dataset:  34%|███▍      | 9455/27412 [00:08<00:14, 1205.09 examples/s]Tokenizing train dataset:  35%|███▌      | 9641/27412 [00:08<00:14, 1213.88 examples/s]Tokenizing train dataset:  36%|███▌      | 9769/27412 [00:08<00:14, 1228.90 examples/s]Tokenizing train dataset:  36%|███▌      | 9899/27412 [00:08<00:14, 1245.82 examples/s]Tokenizing train dataset:  37%|███▋      | 10058/27412 [00:08<00:16, 1055.95 examples/s]Tokenizing train dataset:  37%|███▋      | 10177/27412 [00:08<00:15, 1085.32 examples/s]Tokenizing train dataset:  38%|███▊      | 10295/27412 [00:08<00:15, 1106.62 examples/s]Tokenizing train dataset:  38%|███▊      | 10421/27412 [00:08<00:14, 1146.04 examples/s]Tokenizing train dataset:  39%|███▊      | 10559/27412 [00:08<00:13, 1208.71 examples/s]Tokenizing train dataset:  39%|███▉      | 10690/27412 [00:09<00:13, 1233.40 examples/s]Tokenizing train dataset:  40%|███▉      | 10882/27412 [00:09<00:13, 1244.41 examples/s]Tokenizing train dataset:  40%|████      | 11055/27412 [00:09<00:15, 1064.72 examples/s]Tokenizing train dataset:  41%|████      | 11172/27412 [00:09<00:14, 1087.33 examples/s]Tokenizing train dataset:  41%|████      | 11298/27412 [00:09<00:14, 1128.02 examples/s]Tokenizing train dataset:  42%|████▏     | 11420/27412 [00:09<00:13, 1146.61 examples/s]Tokenizing train dataset:  42%|████▏     | 11552/27412 [00:09<00:13, 1190.92 examples/s]Tokenizing train dataset:  43%|████▎     | 11684/27412 [00:09<00:12, 1225.45 examples/s]Tokenizing train dataset:  43%|████▎     | 11874/27412 [00:10<00:12, 1237.46 examples/s]Tokenizing train dataset:  44%|████▍     | 12000/27412 [00:10<00:14, 1054.71 examples/s]Tokenizing train dataset:  44%|████▍     | 12118/27412 [00:10<00:14, 1079.21 examples/s]Tokenizing train dataset:  45%|████▍     | 12244/27412 [00:10<00:13, 1121.39 examples/s]Tokenizing train dataset:  45%|████▌     | 12421/27412 [00:10<00:13, 1136.58 examples/s]Tokenizing train dataset:  46%|████▌     | 12544/27412 [00:10<00:12, 1155.05 examples/s]Tokenizing train dataset:  46%|████▋     | 12688/27412 [00:10<00:12, 1224.58 examples/s]Tokenizing train dataset:  47%|████▋     | 12820/27412 [00:10<00:11, 1248.01 examples/s]Tokenizing train dataset:  47%|████▋     | 12948/27412 [00:11<00:11, 1254.04 examples/s]Tokenizing train dataset:  48%|████▊     | 13129/27412 [00:11<00:13, 1078.11 examples/s]Tokenizing train dataset:  48%|████▊     | 13265/27412 [00:11<00:12, 1141.84 examples/s]Tokenizing train dataset:  49%|████▉     | 13455/27412 [00:11<00:11, 1180.20 examples/s]Tokenizing train dataset:  50%|████▉     | 13589/27412 [00:11<00:11, 1216.33 examples/s]Tokenizing train dataset:  50%|█████     | 13719/27412 [00:11<00:11, 1236.97 examples/s]Tokenizing train dataset:  51%|█████     | 13849/27412 [00:11<00:10, 1251.37 examples/s]Tokenizing train dataset:  51%|█████     | 13986/27412 [00:11<00:10, 1282.52 examples/s]Tokenizing train dataset:  52%|█████▏    | 14140/27412 [00:12<00:12, 1093.79 examples/s]Tokenizing train dataset:  52%|█████▏    | 14273/27412 [00:12<00:11, 1149.89 examples/s]Tokenizing train dataset:  53%|█████▎    | 14455/27412 [00:12<00:11, 1167.57 examples/s]Tokenizing train dataset:  53%|█████▎    | 14585/27412 [00:12<00:10, 1199.08 examples/s]Tokenizing train dataset:  54%|█████▎    | 14715/27412 [00:12<00:10, 1221.43 examples/s]Tokenizing train dataset:  54%|█████▍    | 14840/27412 [00:12<00:10, 1227.88 examples/s]Tokenizing train dataset:  55%|█████▍    | 14981/27412 [00:12<00:09, 1276.66 examples/s]Tokenizing train dataset:  55%|█████▌    | 15130/27412 [00:12<00:11, 1061.54 examples/s]Tokenizing train dataset:  56%|█████▌    | 15255/27412 [00:13<00:10, 1106.08 examples/s]Tokenizing train dataset:  56%|█████▌    | 15379/27412 [00:13<00:10, 1136.94 examples/s]Tokenizing train dataset:  57%|█████▋    | 15511/27412 [00:13<00:10, 1183.79 examples/s]Tokenizing train dataset:  57%|█████▋    | 15635/27412 [00:13<00:09, 1197.47 examples/s]Tokenizing train dataset:  58%|█████▊    | 15769/27412 [00:13<00:09, 1232.93 examples/s]Tokenizing train dataset:  58%|█████▊    | 15901/27412 [00:13<00:09, 1255.04 examples/s]Tokenizing train dataset:  59%|█████▊    | 16062/27412 [00:13<00:10, 1068.47 examples/s]Tokenizing train dataset:  59%|█████▉    | 16179/27412 [00:13<00:10, 1089.45 examples/s]Tokenizing train dataset:  60%|█████▉    | 16317/27412 [00:13<00:09, 1161.87 examples/s]Tokenizing train dataset:  60%|█████▉    | 16443/27412 [00:14<00:09, 1179.71 examples/s]Tokenizing train dataset:  60%|██████    | 16575/27412 [00:14<00:08, 1212.32 examples/s]Tokenizing train dataset:  61%|██████    | 16704/27412 [00:14<00:08, 1230.92 examples/s]Tokenizing train dataset:  61%|██████▏   | 16832/27412 [00:14<00:08, 1243.23 examples/s]Tokenizing train dataset:  62%|██████▏   | 16970/27412 [00:14<00:08, 1273.12 examples/s]Tokenizing train dataset:  62%|██████▏   | 17121/27412 [00:14<00:10, 1010.47 examples/s]Tokenizing train dataset:  63%|██████▎   | 17245/27412 [00:14<00:09, 1062.45 examples/s]Tokenizing train dataset:  63%|██████▎   | 17374/27412 [00:14<00:09, 1115.20 examples/s]Tokenizing train dataset:  64%|██████▍   | 17498/27412 [00:14<00:08, 1144.58 examples/s]Tokenizing train dataset:  64%|██████▍   | 17635/27412 [00:15<00:08, 1204.22 examples/s]Tokenizing train dataset:  65%|██████▍   | 17772/27412 [00:15<00:07, 1246.44 examples/s]Tokenizing train dataset:  65%|██████▌   | 17912/27412 [00:15<00:07, 1282.47 examples/s]Tokenizing train dataset:  66%|██████▌   | 18058/27412 [00:15<00:08, 1045.17 examples/s]Tokenizing train dataset:  66%|██████▋   | 18182/27412 [00:15<00:08, 1087.18 examples/s]Tokenizing train dataset:  67%|██████▋   | 18305/27412 [00:15<00:08, 1118.43 examples/s]Tokenizing train dataset:  67%|██████▋   | 18430/27412 [00:15<00:07, 1151.03 examples/s]Tokenizing train dataset:  68%|██████▊   | 18570/27412 [00:15<00:07, 1218.17 examples/s]Tokenizing train dataset:  68%|██████▊   | 18761/27412 [00:16<00:07, 1234.26 examples/s]Tokenizing train dataset:  69%|██████▉   | 18890/27412 [00:16<00:06, 1246.74 examples/s]Tokenizing train dataset:  70%|██████▉   | 19056/27412 [00:16<00:07, 1059.24 examples/s]Tokenizing train dataset:  70%|██████▉   | 19183/27412 [00:16<00:07, 1106.62 examples/s]Tokenizing train dataset:  70%|███████   | 19311/27412 [00:16<00:07, 1146.74 examples/s]Tokenizing train dataset:  71%|███████   | 19491/27412 [00:16<00:06, 1160.06 examples/s]Tokenizing train dataset:  72%|███████▏  | 19618/27412 [00:16<00:06, 1184.44 examples/s]Tokenizing train dataset:  72%|███████▏  | 19749/27412 [00:16<00:06, 1215.97 examples/s]Tokenizing train dataset:  73%|███████▎  | 19944/27412 [00:17<00:06, 1239.72 examples/s]Tokenizing train dataset:  73%|███████▎  | 20127/27412 [00:17<00:06, 1075.27 examples/s]Tokenizing train dataset:  74%|███████▍  | 20252/27412 [00:17<00:06, 1113.24 examples/s]Tokenizing train dataset:  75%|███████▍  | 20431/27412 [00:17<00:06, 1133.10 examples/s]Tokenizing train dataset:  75%|███████▍  | 20552/27412 [00:17<00:05, 1150.52 examples/s]Tokenizing train dataset:  75%|███████▌  | 20695/27412 [00:17<00:05, 1217.00 examples/s]Tokenizing train dataset:  76%|███████▌  | 20825/27412 [00:17<00:05, 1234.76 examples/s]Tokenizing train dataset:  76%|███████▋  | 20967/27412 [00:17<00:05, 1283.46 examples/s]Tokenizing train dataset:  77%|███████▋  | 21132/27412 [00:18<00:05, 1076.51 examples/s]Tokenizing train dataset:  78%|███████▊  | 21262/27412 [00:18<00:05, 1124.55 examples/s]Tokenizing train dataset:  78%|███████▊  | 21398/27412 [00:18<00:05, 1178.78 examples/s]Tokenizing train dataset:  79%|███████▊  | 21531/27412 [00:18<00:04, 1214.89 examples/s]Tokenizing train dataset:  79%|███████▉  | 21665/27412 [00:18<00:04, 1247.26 examples/s]Tokenizing train dataset:  80%|███████▉  | 21795/27412 [00:18<00:04, 1259.67 examples/s]Tokenizing train dataset:  80%|███████▉  | 21926/27412 [00:18<00:04, 1270.65 examples/s]Tokenizing train dataset:  80%|████████  | 22066/27412 [00:18<00:04, 1077.34 examples/s]Tokenizing train dataset:  81%|████████  | 22184/27412 [00:18<00:04, 1098.58 examples/s]Tokenizing train dataset:  81%|████████▏ | 22325/27412 [00:19<00:04, 1180.47 examples/s]Tokenizing train dataset:  82%|████████▏ | 22452/27412 [00:19<00:04, 1203.71 examples/s]Tokenizing train dataset:  82%|████████▏ | 22581/27412 [00:19<00:03, 1222.65 examples/s]Tokenizing train dataset:  83%|████████▎ | 22726/27412 [00:19<00:03, 1283.34 examples/s]Tokenizing train dataset:  83%|████████▎ | 22872/27412 [00:19<00:03, 1331.09 examples/s]Tokenizing train dataset:  84%|████████▍ | 23068/27412 [00:19<00:03, 1118.80 examples/s]Tokenizing train dataset:  85%|████████▍ | 23250/27412 [00:19<00:03, 1145.95 examples/s]Tokenizing train dataset:  85%|████████▌ | 23429/27412 [00:20<00:03, 1156.23 examples/s]Tokenizing train dataset:  86%|████████▌ | 23553/27412 [00:20<00:03, 1174.79 examples/s]Tokenizing train dataset:  86%|████████▋ | 23687/27412 [00:20<00:03, 1214.09 examples/s]Tokenizing train dataset:  87%|████████▋ | 23823/27412 [00:20<00:02, 1250.63 examples/s]Tokenizing train dataset:  87%|████████▋ | 23951/27412 [00:20<00:02, 1255.69 examples/s]Tokenizing train dataset:  88%|████████▊ | 24124/27412 [00:20<00:03, 1051.17 examples/s]Tokenizing train dataset:  88%|████████▊ | 24243/27412 [00:20<00:02, 1078.00 examples/s]Tokenizing train dataset:  89%|████████▉ | 24363/27412 [00:20<00:02, 1104.79 examples/s]Tokenizing train dataset:  89%|████████▉ | 24491/27412 [00:20<00:02, 1148.87 examples/s]Tokenizing train dataset:  90%|████████▉ | 24634/27412 [00:21<00:02, 1221.04 examples/s]Tokenizing train dataset:  90%|█████████ | 24762/27412 [00:21<00:02, 1236.95 examples/s]Tokenizing train dataset:  91%|█████████ | 24893/27412 [00:21<00:02, 1254.11 examples/s]Tokenizing train dataset:  91%|█████████▏| 25061/27412 [00:21<00:02, 1033.45 examples/s]Tokenizing train dataset:  92%|█████████▏| 25194/27412 [00:21<00:02, 1099.28 examples/s]Tokenizing train dataset:  92%|█████████▏| 25322/27412 [00:21<00:01, 1142.47 examples/s]Tokenizing train dataset:  93%|█████████▎| 25453/27412 [00:21<00:01, 1183.22 examples/s]Tokenizing train dataset:  93%|█████████▎| 25584/27412 [00:21<00:01, 1213.20 examples/s]Tokenizing train dataset:  94%|█████████▍| 25714/27412 [00:21<00:01, 1235.85 examples/s]Tokenizing train dataset:  94%|█████████▍| 25841/27412 [00:22<00:01, 1243.11 examples/s]Tokenizing train dataset:  95%|█████████▍| 25977/27412 [00:22<00:01, 1270.22 examples/s]Tokenizing train dataset:  95%|█████████▌| 26129/27412 [00:22<00:01, 1060.19 examples/s]Tokenizing train dataset:  96%|█████████▌| 26257/27412 [00:22<00:01, 1113.58 examples/s]Tokenizing train dataset:  96%|█████████▋| 26394/27412 [00:22<00:00, 1176.98 examples/s]Tokenizing train dataset:  97%|█████████▋| 26576/27412 [00:22<00:00, 1183.33 examples/s]Tokenizing train dataset:  97%|█████████▋| 26718/27412 [00:22<00:00, 1239.78 examples/s]Tokenizing train dataset:  98%|█████████▊| 26852/27412 [00:22<00:00, 1265.79 examples/s]Tokenizing train dataset:  98%|█████████▊| 26986/27412 [00:23<00:00, 1281.08 examples/s]Tokenizing train dataset:  99%|█████████▉| 27123/27412 [00:23<00:00, 1056.78 examples/s]Tokenizing train dataset:  99%|█████████▉| 27254/27412 [00:23<00:00, 1117.48 examples/s]Tokenizing train dataset: 100%|█████████▉| 27382/27412 [00:23<00:00, 1156.34 examples/s]Tokenizing train dataset: 100%|██████████| 27412/27412 [00:23<00:00, 1163.48 examples/s]
Packing train dataset:   0%|          | 0/27412 [00:00<?, ? examples/s]Packing train dataset:  33%|███▎      | 9000/27412 [00:00<00:00, 78163.80 examples/s]Packing train dataset:  69%|██████▉   | 19000/27412 [00:00<00:00, 81014.03 examples/s]Packing train dataset: 100%|██████████| 27412/27412 [00:00<00:00, 64941.62 examples/s]Packing train dataset: 100%|██████████| 27412/27412 [00:00<00:00, 68188.17 examples/s]
Tokenizing eval dataset:   0%|          | 0/3046 [00:00<?, ? examples/s]Tokenizing eval dataset:   4%|▍         | 126/3046 [00:00<00:02, 1243.01 examples/s]Tokenizing eval dataset:  10%|█         | 310/3046 [00:00<00:02, 1223.33 examples/s]Tokenizing eval dataset:  14%|█▍        | 436/3046 [00:00<00:02, 1236.02 examples/s]Tokenizing eval dataset:  19%|█▊        | 567/3046 [00:00<00:01, 1258.19 examples/s]Tokenizing eval dataset:  23%|██▎       | 702/3046 [00:00<00:01, 1287.19 examples/s]Tokenizing eval dataset:  28%|██▊       | 845/3046 [00:00<00:01, 1331.69 examples/s]Tokenizing eval dataset:  33%|███▎      | 1000/3046 [00:00<00:01, 1077.29 examples/s]Tokenizing eval dataset:  37%|███▋      | 1127/3046 [00:00<00:01, 1123.62 examples/s]Tokenizing eval dataset:  41%|████      | 1255/3046 [00:01<00:01, 1163.08 examples/s]Tokenizing eval dataset:  46%|████▌     | 1394/3046 [00:01<00:01, 1224.44 examples/s]Tokenizing eval dataset:  50%|█████     | 1526/3046 [00:01<00:01, 1246.27 examples/s]Tokenizing eval dataset:  56%|█████▌    | 1711/3046 [00:01<00:01, 1238.17 examples/s]Tokenizing eval dataset:  60%|██████    | 1838/3046 [00:01<00:00, 1242.33 examples/s]Tokenizing eval dataset:  65%|██████▍   | 1974/3046 [00:01<00:00, 1271.47 examples/s]Tokenizing eval dataset:  70%|███████   | 2136/3046 [00:01<00:00, 1080.42 examples/s]Tokenizing eval dataset:  74%|███████▍  | 2265/3046 [00:01<00:00, 1128.52 examples/s]Tokenizing eval dataset:  79%|███████▊  | 2396/3046 [00:02<00:00, 1171.50 examples/s]Tokenizing eval dataset:  83%|████████▎ | 2520/3046 [00:02<00:00, 1188.40 examples/s]Tokenizing eval dataset:  87%|████████▋ | 2649/3046 [00:02<00:00, 1211.27 examples/s]Tokenizing eval dataset:  91%|█████████▏| 2783/3046 [00:02<00:00, 1238.55 examples/s]Tokenizing eval dataset:  96%|█████████▌| 2917/3046 [00:02<00:00, 1262.56 examples/s]Tokenizing eval dataset: 100%|██████████| 3046/3046 [00:02<00:00, 1000.60 examples/s]Tokenizing eval dataset: 100%|██████████| 3046/3046 [00:02<00:00, 1169.27 examples/s]
Packing eval dataset:   0%|          | 0/3046 [00:00<?, ? examples/s]Packing eval dataset: 100%|██████████| 3046/3046 [00:00<00:00, 67488.54 examples/s]
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.
wandb: Tracking run with wandb version 0.23.0
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /root/HFRL/SFT_DPO/wandb/offline-run-20251117_130724-4gcrq1c4
======== Log a first sample from the processed training set ========
masking area: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ...
  0%|          | 0/4596 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Casting fp32 inputs back to torch.bfloat16 for flash-attn compatibility.
  0%|          | 1/4596 [00:03<4:47:59,  3.76s/it]  0%|          | 2/4596 [00:06<4:10:15,  3.27s/it]  0%|          | 3/4596 [00:09<3:55:57,  3.08s/it]  0%|          | 4/4596 [00:12<3:51:21,  3.02s/it]  0%|          | 5/4596 [00:15<3:48:36,  2.99s/it]  0%|          | 6/4596 [00:18<3:46:59,  2.97s/it]  0%|          | 7/4596 [00:21<3:46:22,  2.96s/it]  0%|          | 8/4596 [00:24<3:45:55,  2.95s/it]  0%|          | 9/4596 [00:27<3:45:42,  2.95s/it]  0%|          | 10/4596 [00:30<3:45:00,  2.94s/it]  0%|          | 11/4596 [00:33<3:45:12,  2.95s/it]  0%|          | 12/4596 [00:36<3:45:51,  2.96s/it]  0%|          | 13/4596 [00:38<3:45:21,  2.95s/it]  0%|          | 14/4596 [00:41<3:46:03,  2.96s/it]  0%|          | 15/4596 [00:44<3:45:31,  2.95s/it]  0%|          | 16/4596 [00:47<3:45:50,  2.96s/it]  0%|          | 17/4596 [00:50<3:45:48,  2.96s/it]  0%|          | 18/4596 [00:53<3:45:45,  2.96s/it]  0%|          | 19/4596 [00:56<3:45:48,  2.96s/it]  0%|          | 20/4596 [00:59<3:45:28,  2.96s/it]  0%|          | 21/4596 [01:02<3:45:24,  2.96s/it]  0%|          | 22/4596 [01:05<3:45:32,  2.96s/it]  1%|          | 23/4596 [01:08<3:46:15,  2.97s/it]  1%|          | 24/4596 [01:11<3:46:11,  2.97s/it]  1%|          | 25/4596 [01:14<3:46:20,  2.97s/it]  1%|          | 26/4596 [01:17<3:46:20,  2.97s/it]  1%|          | 27/4596 [01:20<3:46:17,  2.97s/it]  1%|          | 28/4596 [01:23<3:46:15,  2.97s/it]  1%|          | 29/4596 [01:26<3:46:27,  2.98s/it]  1%|          | 30/4596 [01:29<3:46:06,  2.97s/it]  1%|          | 31/4596 [01:32<3:46:15,  2.97s/it]  1%|          | 32/4596 [01:35<3:45:30,  2.96s/it]  1%|          | 33/4596 [01:38<3:45:58,  2.97s/it]  1%|          | 34/4596 [01:41<3:45:37,  2.97s/it]  1%|          | 35/4596 [01:44<3:45:44,  2.97s/it]  1%|          | 36/4596 [01:47<3:46:09,  2.98s/it]  1%|          | 37/4596 [01:50<3:46:12,  2.98s/it]  1%|          | 38/4596 [01:53<3:46:15,  2.98s/it]  1%|          | 39/4596 [01:56<3:45:43,  2.97s/it]  1%|          | 40/4596 [01:59<3:43:43,  2.95s/it]  1%|          | 41/4596 [02:02<3:44:10,  2.95s/it]  1%|          | 42/4596 [02:04<3:44:37,  2.96s/it]  1%|          | 43/4596 [02:07<3:44:18,  2.96s/it]  1%|          | 44/4596 [02:10<3:44:22,  2.96s/it]  1%|          | 45/4596 [02:13<3:44:08,  2.95s/it]  1%|          | 46/4596 [02:16<3:44:11,  2.96s/it]  1%|          | 47/4596 [02:19<3:44:09,  2.96s/it]  1%|          | 48/4596 [02:22<3:44:59,  2.97s/it]  1%|          | 49/4596 [02:25<3:44:35,  2.96s/it]  1%|          | 50/4596 [02:28<3:44:24,  2.96s/it]  1%|          | 51/4596 [02:31<3:44:09,  2.96s/it]  1%|          | 52/4596 [02:34<3:44:30,  2.96s/it]  1%|          | 53/4596 [02:37<3:44:26,  2.96s/it]  1%|          | 54/4596 [02:40<3:44:26,  2.96s/it]  1%|          | 55/4596 [02:43<3:44:33,  2.97s/it]  1%|          | 56/4596 [02:46<3:44:48,  2.97s/it]  1%|          | 57/4596 [02:49<3:45:16,  2.98s/it]  1%|▏         | 58/4596 [02:52<3:45:23,  2.98s/it]  1%|▏         | 59/4596 [02:55<3:45:03,  2.98s/it]  1%|▏         | 60/4596 [02:58<3:44:57,  2.98s/it]  1%|▏         | 61/4596 [03:01<3:44:22,  2.97s/it]  1%|▏         | 62/4596 [03:04<3:44:11,  2.97s/it]  1%|▏         | 63/4596 [03:07<3:44:19,  2.97s/it]  1%|▏         | 64/4596 [03:10<3:43:55,  2.96s/it]  1%|▏         | 65/4596 [03:13<3:43:39,  2.96s/it]  1%|▏         | 66/4596 [03:16<3:44:06,  2.97s/it]  1%|▏         | 67/4596 [03:19<3:44:10,  2.97s/it]  1%|▏         | 68/4596 [03:22<3:42:10,  2.94s/it]  2%|▏         | 69/4596 [03:25<3:42:40,  2.95s/it]  2%|▏         | 70/4596 [03:27<3:42:28,  2.95s/it]  2%|▏         | 71/4596 [03:30<3:42:33,  2.95s/it]  2%|▏         | 72/4596 [03:33<3:42:38,  2.95s/it]  2%|▏         | 73/4596 [03:36<3:43:03,  2.96s/it]  2%|▏         | 74/4596 [03:39<3:43:08,  2.96s/it]  2%|▏         | 75/4596 [03:42<3:43:35,  2.97s/it]