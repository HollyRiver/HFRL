wandb: Detected [huggingface_hub.inference, openai] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.76s/it]
You are using a per_device_train_batch_size of 1 with padding-free training. Using a batch size of 1 anihilate the benefits of padding-free training. Please consider increasing the batch size to at least 2.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.
  0%|          | 0/3564 [00:00<?, ?it/s]/root/anaconda3/envs/RLHF/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 25%|██▌       | 891/3564 [35:43<1:21:23,  1.83s/it]
100%|██████████| 198/198 [01:57<00:00,  1.84it/s]
{'loss': 0.6931, 'grad_norm': 7.776622772216797, 'learning_rate': 9.999873360091987e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -39.38523483276367, 'logps/rejected': -45.0251579284668, 'logits/chosen': -1.0263231992721558, 'logits/rejected': -1.0306603908538818, 'epoch': 0.25}
{'loss': 0.6931, 'grad_norm': 6.480200290679932, 'learning_rate': 9.894823780672369e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -38.47188186645508, 'logps/rejected': -44.818687438964844, 'logits/chosen': -1.0325403213500977, 'logits/rejected': -1.02412748336792, 'epoch': 0.5}
/root/anaconda3/envs/RLHF/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 50%|█████     | 1782/3564 [1:15:26<55:03,  1.85swandb: WARNING URL not available in offline run
/root/anaconda3/envs/RLHF/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
No files have been modified since last commit. Skipping to prevent empty commit.
 75%|███████▌  | 2673/3564 [1:53:11<31:03,  2.09swandb: WARNING URL not available in offline run
/root/anaconda3/envs/RLHF/lib/python3.12/site-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
No files have been modified since last commit. Skipping to prevent empty commit.
100%|██████████| 3564/3564 [2:30:55<00:00,  2.57swandb: WARNING URL not available in offline run
100%|██████████| 3564/3564 [2:30:59<00:00,  2.54s/it]
No files have been modified since last commit. Skipping to prevent empty commit.
wandb: WARNING URL not available in offline run
Processing Files (4 / 4)      : 100%|██████████| 1.36GB / 1.36GB, 1.45MB/s
New Data Upload               : 100%|██████████| 16.7MB / 16.7MB, 1.45MB/s
  ...-lr1e-7/training_args.bin: 100%|██████████| 6.93kB / 6.93kB
  ...dpo-lr1e-7/tokenizer.json: 100%|██████████| 17.2MB / 17.2MB
  ...adapter_model.safetensors: 100%|██████████|  671MB /  671MB
  ...adapter_model.safetensors: 100%|██████████|  671MB /  671MB
{'eval_loss': 0.6931471228599548, 'eval_runtime': 118.2206, 'eval_samples_per_second': 1.675, 'eval_steps_per_second': 1.675, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -40.02629089355469, 'eval_logps/rejected': -46.276607513427734, 'eval_logits/chosen': -1.0379081964492798, 'eval_logits/rejected': -1.0212575197219849, 'epoch': 1.0}
{'loss': 0.6931, 'grad_norm': 6.469942092895508, 'learning_rate': 9.123134776696607e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -38.8166389465332, 'logps/rejected': -46.356624603271484, 'logits/chosen': -1.0344619750976562, 'logits/rejected': -1.027862787246704, 'epoch': 1.0}
{'loss': 0.6931, 'grad_norm': 8.744795799255371, 'learning_rate': 8.490121630474697e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -39.362220764160156, 'logps/rejected': -44.08564376831055, 'logits/chosen': -1.0298655033111572, 'logits/rejected': -1.0253350734710693, 'epoch': 1.25}
{'loss': 0.6931, 'grad_norm': 4.808823108673096, 'learning_rate': 7.726814205493419e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -38.25525665283203, 'logps/rejected': -45.730865478515625, 'logits/chosen': -1.0281647443771362, 'logits/rejected': -1.026309847831726, 'epoch': 1.5}
{'loss': 0.6931, 'grad_norm': 8.612950325012207, 'learning_rate': 6.866473553542768e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -38.362457275390625, 'logps/rejected': -44.674129486083984, 'logits/chosen': -1.0410470962524414, 'logits/rejected': -1.0367624759674072, 'epoch': 1.75}
{'eval_loss': 0.6931471228599548, 'eval_runtime': 118.2055, 'eval_samples_per_second': 1.675, 'eval_steps_per_second': 1.675, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -40.02629089355469, 'eval_logps/rejected': -46.276607513427734, 'eval_logits/chosen': -1.0379081964492798, 'eval_logits/rejected': -1.0212575197219849, 'epoch': 2.0}
{'loss': 0.6931, 'grad_norm': 15.091236114501953, 'learning_rate': 5.946588940474274e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -39.18269729614258, 'logps/rejected': -45.31436538696289, 'logits/chosen': -1.031310796737671, 'logits/rejected': -1.0277405977249146, 'epoch': 2.0}
{'loss': 0.6931, 'grad_norm': 6.735435485839844, 'learning_rate': 5.007244254842856e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -39.15451431274414, 'logps/rejected': -45.66184616088867, 'logits/chosen': -1.02866530418396, 'logits/rejected': -1.0239338874816895, 'epoch': 2.25}
{'loss': 0.6931, 'grad_norm': 5.013091564178467, 'learning_rate': 4.089371356099782e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -38.71144485473633, 'logps/rejected': -44.02089309692383, 'logits/chosen': -1.0353062152862549, 'logits/rejected': -1.0318245887756348, 'epoch': 2.5}
{'loss': 0.6931, 'grad_norm': 7.022671222686768, 'learning_rate': 3.232966472530765e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -37.030189514160156, 'logps/rejected': -42.92849349975586, 'logits/chosen': -1.0314384698867798, 'logits/rejected': -1.0301868915557861, 'epoch': 2.75}
{'eval_loss': 0.6931471228599548, 'eval_runtime': 118.0989, 'eval_samples_per_second': 1.677, 'eval_steps_per_second': 1.677, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -40.02629089355469, 'eval_logps/rejected': -46.276607513427734, 'eval_logits/chosen': -1.0379081964492798, 'eval_logits/rejected': -1.0212575197219849, 'epoch': 3.0}
{'loss': 0.6931, 'grad_norm': 9.53573226928711, 'learning_rate': 2.475347369237185e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -39.64713668823242, 'logps/rejected': -46.83108139038086, 'logits/chosen': -1.0364185571670532, 'logits/rejected': -1.0315576791763306, 'epoch': 3.0}
{'loss': 0.6931, 'grad_norm': 7.946441173553467, 'learning_rate': 1.849527229907591e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -38.66840744018555, 'logps/rejected': -44.890071868896484, 'logits/chosen': -1.031008005142212, 'logits/rejected': -1.028748869895935, 'epoch': 3.25}
{'loss': 0.6931, 'grad_norm': 7.284902572631836, 'learning_rate': 1.3827761103336891e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -39.19749069213867, 'logps/rejected': -45.245094299316406, 'logits/chosen': -1.0387283563613892, 'logits/rejected': -1.0337810516357422, 'epoch': 3.5}
{'loss': 0.6931, 'grad_norm': 4.418935775756836, 'learning_rate': 1.0954326482033907e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -38.332611083984375, 'logps/rejected': -44.18290328979492, 'logits/chosen': -1.035557508468628, 'logits/rejected': -1.025744080543518, 'epoch': 3.75}
{'eval_loss': 0.6931471228599548, 'eval_runtime': 118.1593, 'eval_samples_per_second': 1.676, 'eval_steps_per_second': 1.676, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/chosen': -40.02629089355469, 'eval_logps/rejected': -46.276607513427734, 'eval_logits/chosen': -1.0379081964492798, 'eval_logits/rejected': -1.0212575197219849, 'epoch': 4.0}
{'train_runtime': 9059.1803, 'train_samples_per_second': 0.786, 'train_steps_per_second': 0.393, 'train_loss': 0.6931459574587016, 'epoch': 4.0}
Working Time: 2:31:55
========== 학습 종료 ==========