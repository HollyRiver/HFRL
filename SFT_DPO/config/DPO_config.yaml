## ScriptArguments
model_name: "results/test"                            ## 사용할 모델명 (SFT 완료 모델)
dataset_path: "./data"                                ## 데이터셋 저장 경로

## DPOConfig
max_length: 1024                                      ## 모델이 수용 가능한 최대 시퀀스 길이
max_prompt_length: 1024                               ## 최대 프롬프트 시퀀스 길이
output_dir: "./results/dpo-test"                      ## 튜닝된 모델 저장 위치
report_to: "wandb"                                    ## 튜닝 로그 리포트 (토큰 등록 필요)
run_name: "dpo-test"                                  ## wandb 전달 이름
learning_rate: 5e-7                                   ## update matrix 학습률. 1e-7을 표준으로 증가시키며 확인
lr_scheduler_type: "cosine_with_restarts"             ## 코사인 스케줄러 사용 + 학습률 초기화
lr_scheduler_kwargs:
  num_cycles: 3                                       ## 코사인 곡선 사이클 횟수 지정
num_train_epochs: 2                                   ## 에폭
per_device_train_batch_size: 4                        ## GPU당 배치 사이즈
per_device_eval_batch_size: 4                         ## GPU당 배치 사이즈(평가)
gradient_accumulation_steps: 2                        ## 그래디언트를 모아두었다가 한꺼번에 적용: 배치 사이즈를 키우는 효과
do_eval: true                                         ## evaluation loss 계산 (전체 eval dataset을 대상으로 산출하므로, 꽤 많은 시간이 소요됨.)
eval_steps: 500
eval_strategy: "steps"                                ## epoch마다 모델이 저장되므로, 실제로는 이를 기준으로 계산하는 전략이 유효할 것으로 판단됨
optim: "adamw_torch_fused"                            ## optimizer 설정
logging_steps: 100                                    ## 로그 산출 빈도
save_strategy: "epoch"                                ## 에폭별 모델 저장
weight_decay: 0.01                                    ## adamw optimizer에서 l2-norm weight decay. 과적합 방지.
max_grad_norm: 0.5                                    ## 그래디언트 클리핑의 임계값 지정. 모든 파라미터의 그래디언트에 대하여 l2-norm의 임계값. exploding 방지. 낮게 설정하면 훈련 속도 느려질 수 있음.
warmup_ratio: 0.06                                    ## 초기 학습률 warmup 단계의 비중 설정: 총 스텝 중 비율. 데이터셋과 모델 크기에 따라 조정. (모델와 데이터셋이 클수록 warmup_step을 키워주면 효과적)
bf16: true                                            ## bf16 정밀도 활성화: 모델 내부 연산 수행
tf32: true                                            ## nvidia TensorFormat-32 활성화: fp32로 수행되어야 하는 일부 연산을 가속
gradient_checkpointing: true                          ## 그래디언트를 캐시에 저장하지 않고 필요할 때마다 계산하여 GPU 절약
dataloader_num_workers: 4                             ## 데이터로더 워커 수: 보통 GPU 개수 * 4 정도 사용한다고 함
remove_unused_columns: false                          ##
beta: 0.1                                             ## DPO loss 온도. 적을수록 reference model을 무시
loss_type: "apo_zero"                                 ##
padding_free: true                                    ## 패딩없이 텍스트를 하나의 시퀀스로  flash attention 사용 필수

## LoraArguments
r: 32                                                 ## update matrix의 rank. 작을수록 많이 압축하여 품질 저하됨, 메모리 많이 할당됨
lora_alpha: 16                                        ## ∆Weight scaling factor. lora_alpha / r로 스케일링되며, 학습률 조정. 논문에서는 16을 고정하는 것을 추천했으나, 다른 값이 효과적일 때도 많다. r이 좀 커질 때 1/2수준으로 설정하면 적합
lora_dropout: 0.05                                    ## update matrics에서 dropout 적용 확률
bias: "none"                                          ## update matrix에 bias를 학습할 것인지 선택
task_type: "CAUSAL_LM"                                ## 튜닝 모형의 유형 지정
target_modules:                                       ## 적용할 트랜스포머 모듈. 기본(None)은 ["q_proj", "v_proj"]만 사용. embed_tokens와 lm_head는 제외
  - "q_proj"                                          ## Query
  - "k_proj"                                          ## Key
  - "v_proj"                                          ## Value
  - "o_proj"                                          ## Output
  - "up_proj"                                         ##
  - "down_proj"                                       ##
  - "gate_proj"                                       ##
  # - "embed_tokens"
  # - "lm_head"